{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human-level Control through Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We analyze the deep Q-learning algorithm devised by the research team of DeepMind. The authors from this paper created their own DQN where the novelty lies in using pixels and scores as input to the neural network compared to lower-dimensional representations, as used in notebook **Naive Deep Q-learning**. For this, they made a shift from simple linear layers to convolutional layers to process the information. Convolutional neural networks perform a mathematical operation called a convolution on the input images. The effect of a convolution is that we start with large-scale images and end up with smaller images that capture the features and paters from that image. The convolution itself is performed by sliding a smaller matrix called a filter over the larger matrix (the input image) and taking the matrix product each time. The resulting numbers are then stored as a new matrix witch will have a smaller size than the original matrix. In reality, we use several filters for each layer. The input image is passed to the first convolutional layer, and the filters are shoved over the image, resulting in smaller matrices. Just like the simple linear layer, we pass the output of our convolutions to an activation function. The smaller activated matrices serve as feature inputs for our regular linear layers.\n",
    "\n",
    "They tested their algorithm on 49 games from the OpenAI Atari library, and the algorithm was able to outperform all previously created algorithms without hyperparameter tuning. The paper states that reinforcement Learning is unstable when a nonlinear approximator function is used to represents the Q-function. We observed this instability in our own naive implementation of deep Q-learning on the cart-and-pole problem. The agent learns to balance the pole and seemingly for no reason drops its performance. This instability has various root causes. The first reason is that there is a correlation in the sequence of observations. Small updates to the Q-value may drastically change the policy, data distributions, and the correlation between the action-values $Q(s, a)$ and the target value $r + \\gamma \\max Q(s', a')$. Correlation in the sequence of observations means that the card-and-pole would start in some high-dimensional space, take some action and not leave that region of space. Should the action-value function Q change significantly, we get a significant change in the $r + \\gamma \\max Q(s', a')$, and we get catapulted to some adjacent region parameter space that our neural network has no information. The second factor is that there is a correlation between the action-value $Q(s, a)$ and the target value $r + \\gamma \\max Q(s', a')$. Since we use the same network to both select an action and tell us its value, we effectively chase a moving target.\n",
    "\n",
    "(Mnih et al., 2015) addresses these instabilities with a novel variant of Q-learning witch uses two key ideas. First, they introduce the notion of replay memory that randomizes over the data, thereby removing correlation in the observation sequence and smoothing over changes in the data distribution. Second, they use an iterative update that resolves the action-value $Q(s, a)$ towards the target value $r + \\gamma \\max Q(s', a')$, which is only periodically updated and thereby reducing correlations with the target. They parametrize the value function $Q(s, a, \\theta_i)$ using a deep convolutional neural network in withs $\\theta_i$ are the policy network's weights iteration i.\n",
    "\n",
    "To perform experience replay we store the agents experience $e_t=(s_t,a_t,r_{t+1},s_{t+1})$ at each timestep t in the dataset $D_t=(e_1, e_2, .., e_t)$. We apply Q-learning updates on samples or mini-batches drawn uniformly at random from the pool of stored samples during learning. The uniform sampling guarantees that we do not get a stream of observations from a single episode, and hence we break the correlations.\n",
    "\n",
    "Our policy neural network gets updated every timestep, as we expect with temporal difference learning, but the target network gets updated only periodically by directly copying the policy neural network's weights. We do not do backpropagation on the target network but only on the policy network.\n",
    "\n",
    "As mentioned before, this notebook is a replica of the work done in the paper, so we use the same network architecture as proposed. The neural network input consists of an 8 by 84 $\\times$ 84 $\\times$ image produced by first preprocessing the observation returned by the OpenAI Atari environment. The preprocessing of the observation is not central to the learning, and we invite the reader to consult the GitHub code \\cite{GitHub}. The first hidden layer convolves 32 filters of 8 $\\times$ 8 with stride 4, followed by a rectified nonlinearity. The second hidden layer convolves 64 filters of 4 $\\times$ 4, with side 2, again followed by rectified nonlinearity. This is followed by a third convolutional layer that convolves 64 filters of 3 $\\times$ 3 with stride 1 followed by a rectifier. The final hidden layer is fully connected and consists of 512 rectified units. The output layer is a fully-connected layer with a single output for each valid action.\n",
    "\n",
    "We test our algorithms using the Atari 2600 Pong environment, where the goal is to maximize the score of the Pong game. In this environment, the observation is a two-dimensional array of three-element tuples (RGB). The shape of the array is (210, 160, 3). Each action is repeated four times on every four skipped frames. \n",
    "\n",
    "**References:**\n",
    "- https://gym.openai.com/envs/Pong-v0/\n",
    "- https://github.com/openai/gym/tree/master/gym/wrappers\n",
    "- https://github.com/philtabor/Deep-Q-Learning-Paper-To-Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch as T\n",
    "\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import collections \n",
    "import cv2\n",
    "\n",
    "from ipynb.fs.full.Plotting import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derives from: Gym.Wrapper.\n",
    "# Repeating actions over k'th skipped frames and taking max off the previous two frames to overcome flikkering. \n",
    "\n",
    "class RepeatAction(gym.Wrapper):\n",
    "    def __init__(self, env, repeat, clip_reward):\n",
    "        super(RepeatAction, self).__init__(env)\n",
    "        \n",
    "        self.repeat = repeat\n",
    "        self.clip_reward = clip_reward\n",
    "        \n",
    "        self.shape = env.observation_space.low.shape\n",
    "        self.frame_buffer = np.zeros_like((2, self.shape))\n",
    "\n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        score = 0.0\n",
    "\n",
    "        # Repeat actions in the environment.\n",
    "        for i in range(self.repeat):\n",
    "            observation, reward, done, info = self.env.step(action)\n",
    "            \n",
    "            # Clip reward.\n",
    "            if self.clip_reward:\n",
    "                reward = np.clip(np.array([reward]), -1, 1)[0]  \n",
    "            score += reward\n",
    "            self.frame_buffer[i % 2] = observation\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        max_frame = np.maximum(self.frame_buffer[0], self.frame_buffer[1]) # Return max frame.\n",
    "        \n",
    "        return max_frame, score, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        observation = self.env.reset()\n",
    "        self.frame_buffer = np.zeros_like((2,self.shape))\n",
    "        self.frame_buffer[0] = observation\n",
    "\n",
    "        return observation\n",
    "\n",
    "# Derives from: Gym.ObservationWrapper.\n",
    "# Reshape frame and convert to grayscale.\n",
    "\n",
    "class PreprocessFrame(gym.ObservationWrapper):\n",
    "    def __init__(self, env, shape):\n",
    "        super(PreprocessFrame, self).__init__(env)\n",
    "        \n",
    "        self.shape = (shape[2], shape[0], shape[1]) # PyTorch expects image channels first.\n",
    "        self.observation_space = gym.spaces.Box(low = 0.0, high = 1.0, shape = self.shape, dtype = np.float32)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        gray_frame = cv2.cvtColor(observation, cv2.COLOR_RGB2GRAY) # Convert to grayscale.\n",
    "        resized_frame = cv2.resize(gray_frame, self.shape[1:], interpolation = cv2.INTER_AREA) # Resize frame.\n",
    "        new_observation = np.array(resized_frame, dtype = np.uint8).reshape(self.shape) # Convert type.\n",
    "        new_observation = new_observation / 255.0 # RGB ranges from 0 to 255, observation space ranges from 0 to 1.\n",
    "\n",
    "        return new_observation\n",
    "\n",
    "# Derives from: Gym.ObservationWrapper.\n",
    "# Stack frames.\n",
    "\n",
    "class StackFrames(gym.ObservationWrapper):\n",
    "    def __init__(self, env, repeat):\n",
    "        super(StackFrames, self).__init__(env)\n",
    "        \n",
    "        self.stack = collections.deque(maxlen = repeat)\n",
    "        self.observation_space = gym.spaces.Box(env.observation_space.low.repeat(repeat, axis = 0),\n",
    "                                                env.observation_space.high.repeat(repeat, axis = 0),\n",
    "                                                dtype = np.float32)\n",
    "        \n",
    "    def reset(self):\n",
    "        observation = self.env.reset()\n",
    "        self.stack.clear()\n",
    "\n",
    "        for _ in range(self.stack.maxlen):\n",
    "            self.stack.append(observation)\n",
    "\n",
    "        return np.array(self.stack).reshape(self.observation_space.low.shape)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        self.stack.append(observation)\n",
    "\n",
    "        return np.array(self.stack).reshape(self.observation_space.low.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(env_name, shape = (84, 84, 1), repeat = 4, clip_rewards = False):\n",
    "    env = gym.make(env_name)\n",
    "    env = RepeatAction(env, repeat, clip_rewards)\n",
    "    env = PreprocessFrame(env, shape)\n",
    "    env = StackFrames(env, repeat)\n",
    "\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory():\n",
    "    def __init__(self, observation_space, capacity):\n",
    "        \n",
    "        self.observation_space = observation_space \n",
    "        self.capacity = capacity\n",
    "        self.replay_counter = 0\n",
    "        \n",
    "        self.observation_memory = np.zeros((self.capacity, *self.observation_space), dtype = np.float32)\n",
    "        self.action_memory = np.zeros(self.capacity, dtype = np.int64)\n",
    "        self.reward_memory = np.zeros(self.capacity, dtype = np.float32)\n",
    "        self.next_observation_memory = np.zeros((self.capacity, *self.observation_space), dtype = np.float32)\n",
    "        self.terminal_memory = np.zeros(self.capacity, dtype = np.bool)\n",
    "\n",
    "    def store_experience(self, observation, action, reward, next_observation, done):\n",
    "        index = self.replay_counter % self.capacity\n",
    "        self.observation_memory[index] = observation\n",
    "        self.action_memory[index] = action\n",
    "        self.reward_memory[index] = reward\n",
    "        self.next_observation_memory[index] = next_observation\n",
    "        self.terminal_memory[index] = done\n",
    "        self.replay_counter += 1\n",
    "\n",
    "    def sample_memory(self, batch_size):\n",
    "        max_mem = min(self.replay_counter, self.capacity)\n",
    "        batch = np.random.choice(max_mem, batch_size, replace = False)\n",
    "\n",
    "        observations = self.observation_memory[batch]\n",
    "        actions = self.action_memory[batch]\n",
    "        rewards = self.reward_memory[batch]\n",
    "        next_observations = self.next_observation_memory[batch]\n",
    "        terminals = self.terminal_memory[batch]\n",
    "\n",
    "        return observations, actions, rewards, next_observations, terminals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Q-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQNetwork(nn.Module):\n",
    "    def __init__(self, observation_space, action_space, learning_rate):\n",
    "        super(DeepQNetwork, self).__init__()\n",
    "        \n",
    "        self.observation_space = observation_space\n",
    "        self.action_space = action_space\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.conv1 = nn.Conv2d(self.observation_space[0], 32, 8, stride = 4)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 4, stride = 2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, stride = 1)\n",
    "\n",
    "        self.fc_observation_space = self.calculate_convolutional_output(self.observation_space)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.fc_observation_space, 512)\n",
    "        self.fc2 = nn.Linear(512, self.action_space)\n",
    "\n",
    "        self.optimizer = optim.RMSprop(self.parameters(), lr = self.learning_rate)\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.to(self.device)\n",
    "\n",
    "    def calculate_convolutional_output(self, observation_space):\n",
    "        state = T.zeros(1, *observation_space)\n",
    "        dims = self.conv1(state)\n",
    "        dims = self.conv2(dims)\n",
    "        dims = self.conv3(dims)\n",
    "        return int(np.prod(dims.size()))\n",
    "\n",
    "    def forward(self, observation):\n",
    "        conv1 = F.relu(self.conv1(observation))\n",
    "        conv2 = F.relu(self.conv2(conv1))\n",
    "        conv3 = F.relu(self.conv3(conv2))\n",
    "        conv_state = conv3.view(conv3.size()[0], -1) # Conv3 shape is BS x n_filters x H x W.\n",
    "        flat1 = F.relu(self.fc1(conv_state)) # Conv_state shape is BS x (n_filters * H * W).\n",
    "        actions = self.fc2(flat1)\n",
    "\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, observation_space, action_space, learning_rate = 0.0001, discount_rate = 0.99, exploration_rate = 1.0,\n",
    "                 max_exploration_rate = 1, min_exploration_rate = 0.1, exploration_decay_rate = 0.01,\n",
    "                 batch_size = 32, replace = 1000, capacity = 50000):\n",
    "        \n",
    "        self.episode = 0\n",
    "        self.learn_counter = 0 \n",
    "        \n",
    "        self.observation_space = observation_space\n",
    "        self.action_space = action_space\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_rate = discount_rate\n",
    "        \n",
    "        self.exploration_rate = exploration_rate\n",
    "        self.max_exploration_rate = max_exploration_rate\n",
    "        self.min_exploration_rate = min_exploration_rate\n",
    "        self.exploration_decay_rate = exploration_decay_rate\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.replace = replace\n",
    "        self.capacity = capacity\n",
    "        \n",
    "        self.replay_memory = ReplayMemory(self.observation_space, self.capacity)\n",
    "        self.policy_network = DeepQNetwork(self.observation_space, self.action_space, self.learning_rate)\n",
    "        self.target_network = DeepQNetwork(self.observation_space, self.action_space, self.learning_rate)\n",
    "        \n",
    "    def choice_action(self, observation):\n",
    "        exploration_rate_threshold = np.random.random()\n",
    "        if exploration_rate_threshold > self.exploration_rate:\n",
    "            observation = T.tensor([observation], dtype = T.float).to(self.policy_network.device)\n",
    "            actions = self.policy_network.forward(observation) # Q-values for action in state.\n",
    "            action = T.argmax(actions).item() # Best Q-value for action in state.\n",
    "        else:\n",
    "            action = np.random.choice(self.action_space) # Random Action.\n",
    "            \n",
    "        return action\n",
    "    \n",
    "    def store_experience(self, observation, action, reward, next_observation, done):\n",
    "        self.replay_memory.store_experience(observation, action, reward, next_observation, done)\n",
    "\n",
    "    def sample_memory(self):\n",
    "        observations, actions, rewards, next_observations, terminals = self.replay_memory.sample_memory(self.batch_size)\n",
    "        \n",
    "        return observations, actions, rewards, next_observations, terminals\n",
    "\n",
    "    def replace_target_network(self):\n",
    "        if self.learn_counter % self.replace == 0:\n",
    "            self.target_network.load_state_dict(self.policy_network.state_dict())\n",
    "            \n",
    "    def decrease_exploration_rate(self):\n",
    "        self.exploration_rate = self.min_exploration_rate + \\\n",
    "            (self.max_exploration_rate - self.min_exploration_rate) * np.exp(- self.exploration_decay_rate * self.episode)\n",
    "        self.episode += 1\n",
    "\n",
    "    def learn(self):\n",
    "        if self.replay_memory.replay_counter < self.batch_size:\n",
    "            return\n",
    "        \n",
    "        # Increment learn counter.\n",
    "        self.learn_counter += 1\n",
    "        \n",
    "        # Set gradient to zero.\n",
    "        self.policy_network.optimizer.zero_grad()\n",
    "        \n",
    "        # Copy policy network to target network after.\n",
    "        self.replace_target_network()\n",
    "\n",
    "        # Sample from replay memory.\n",
    "        observations, actions, rewards, next_observations, terminals = self.sample_memory()\n",
    "        \n",
    "        # Convert to tensors.\n",
    "        observations = T.tensor(observations).to(self.policy_network.device)\n",
    "        actions = T.tensor(actions).to(self.policy_network.device)\n",
    "        rewards = T.tensor(rewards).to(self.policy_network.device)\n",
    "        next_observations = T.tensor(next_observations).to(self.policy_network.device)\n",
    "        terminals = T.tensor(terminals).to(self.policy_network.device)\n",
    "        \n",
    "        indices = np.arange(self.batch_size)\n",
    "\n",
    "        # Calculate loss using Bellman equation.\n",
    "        q_pred = self.policy_network.forward(observations)[indices, actions]\n",
    "        q_next = self.target_network.forward(next_observations).max(dim = 1)[0]\n",
    "        q_next[terminals] = 0.0\n",
    "        q_target = rewards + self.discount_rate * q_next\n",
    "        loss = self.policy_network.loss(q_target, q_pred).to(self.policy_network.device)\n",
    "        \n",
    "        # Optimizer in action.\n",
    "        loss.backward()\n",
    "        self.policy_network.optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "step = 0\n",
    "episodes = 500\n",
    "\n",
    "env = make_env('PongNoFrameskip-v4')\n",
    "agent = Agent(env.observation_space.shape, env.action_space.n)\n",
    "\n",
    "scores, exploration_rate_history, steps = [], [], []\n",
    "\n",
    "for i in range(episodes):\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    score = 0.0\n",
    "    \n",
    "    while not done:\n",
    "        action = agent.choice_action(observation)\n",
    "        next_observation, reward, done, info = env.step(action)\n",
    "        agent.store_experience(observation, action, reward, next_observation, done)\n",
    "        agent.learn()\n",
    "        observation = next_observation\n",
    "        score += reward\n",
    "        step += 1\n",
    "    \n",
    "    scores.append(score)\n",
    "    steps.append(step)\n",
    "    exploration_rate_history.append(agent.exploration_rate)\n",
    "    agent.decrease_exploration_rate()\n",
    "\n",
    "plot_learning_curve(steps, scores, exploration_rate_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent starts to learn as the epsilon decreases, but the majority of the learning happens in the greedy face. By around 500.000 steps, the agent has topped out its score with some oscillation around 15.5 or 16. We manage this with only a few hours of training on modest hardware. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
